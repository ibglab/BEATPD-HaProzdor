{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session score\n",
    "Generate a single score for the session based on the different segment scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(asctime)s: %(message)s')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, SelectFromModel, f_regression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "\n",
    "import imblearn\n",
    "import getpass\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import Classification_utils as helpFunc\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set scoring parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runClassification(train, test, labelName, useFirstHalf, selectFeatures, fixClassImbalance = 'none', seed=np.nan, regressionModel = False):\n",
    "    #use only first half of session\n",
    "\n",
    "    if useFirstHalf:\n",
    "        train = helpFunc.cutSession(train)\n",
    "        test = helpFunc.cutSession(test)\n",
    "\n",
    "    train, _ = helpFunc.splitData(train, labelName=labelName, testSize=testSize, seed=seed)\n",
    "    # remove Nans\n",
    "    train = train.dropna(subset=[labelName])\n",
    "    test = test.dropna(subset=[labelName])\n",
    "\n",
    "    # Get X and y (train and test ) and labels\n",
    "    # reassign indexes of train and test  (which changed after manipulations) to match simple range\n",
    "    train.index = range(len(train))\n",
    "    test.index = range(len(test))\n",
    "\n",
    "    X_train = train.drop(['sessionID'] + y_fields, axis=1)\n",
    "    y_train = train[labelName]\n",
    "    X_test = test.drop(['sessionID']  + y_fields, axis=1)\n",
    "\n",
    "\n",
    "    # Normalization\n",
    "    min_max_scaler = preprocessing.MinMaxScaler(feature_range = (-1,1))\n",
    "    min_max_scaler.fit(pd.concat([X_train, X_test], ignore_index=True))\n",
    "    X_train= min_max_scaler.transform(X_train)\n",
    "    X_test= min_max_scaler.transform(X_test)\n",
    "\n",
    "    # feature selection\n",
    "    selFeat = selectFeatures.fit(X_train, y_train)\n",
    "    # apply feature selection\n",
    "    X_train = selFeat.transform(X_train)\n",
    "    X_test = selFeat.transform(X_test)\n",
    "\n",
    "    # handle class imbalance\n",
    "    if fixClassImbalance != 'none':\n",
    "        if fixClassImbalance=='SMOTEENN':\n",
    "            smote_enn = imblearn.combine.SMOTEENN(random_state=0)\n",
    "            X_train, y_train = smote_enn.fit_resample(X_train, y_train)\n",
    "        elif fixClassImbalance == 'RandomUnderSampler':\n",
    "            rus = imblearn.under_sampling.RandomUnderSampler(random_state=42)\n",
    "            X_train, y_train = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "    # run models\n",
    "    if regressionModel:\n",
    "        clf = RandomForestRegressor(random_state = seed)\n",
    "    else:\n",
    "        clf = RandomForestClassifier(random_state = seed)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    all_y_pred = clf.predict(X_test)\n",
    "\n",
    "    sessionIDs = test['sessionID'].unique()\n",
    "    y_pred = np.zeros(len(sessionIDs))\n",
    "\n",
    "    for i, sessionID in enumerate(sessionIDs):\n",
    "        sessionIdx = test.index[test['sessionID']==sessionID].tolist()\n",
    "        y_pred[i] = all_y_pred[sessionIdx].astype(np.intp).mean()\n",
    "\n",
    "    d = {'sessionID': sessionIDs, 'y_pred': y_pred}\n",
    "    y_predictions = pd.DataFrame(data=d)\n",
    "\n",
    "    return sessionIDs, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SessionScoreSeed(seed):\n",
    "    all_results, all_pred = {}, {}\n",
    "    # load tables\n",
    "    for i, labelName in enumerate(y_fields):\n",
    "\n",
    "        resFile = os.path.join('features_seeds_summary', dataset.lower(), test_rand, labelName+'_allResults_seed'+str(seed)+'.csv')\n",
    "        if dataset == 'cis':\n",
    "            predFile = os.path.join('features', 'BEAT-PD_SC' + str(i+1) + '_'+labelName +'_'+test_rand+'.csv')\n",
    "        else:\n",
    "            predFile = os.path.join(outputFolder, 'BEAT-PD_SC' + str(i+1) + '_'+labelName +'_'+ str(seed) + '.csv')\n",
    "        \n",
    "        logging.info(f'Seed {seed} Score {labelName}: Input {resFile} Output {predFile}')\n",
    "        dfRes = pd.read_csv(resFile)\n",
    "        dfRes = dfRes.set_index(list(dfRes.columns[[0]]))\n",
    "        dfPred = pd.read_csv(predFile)\n",
    "        \n",
    "        all_results[labelName] = dfRes\n",
    "        all_pred[labelName]= dfPred\n",
    "\n",
    "    for id in subject_ids:\n",
    "        subjectTrainFolderName = dataSetFolderName + str(id)\n",
    "        subjectTestFolderName = dataSetFolderName + str(id) + '_test'\n",
    "        \n",
    "        data= pd.read_csv(os.path.join(subjectTrainFolderName, feature_file), delim_whitespace=True, header=None, mangle_dupe_cols=True)\n",
    "        data['sessionID'] = pd.read_csv(os.path.join(subjectTrainFolderName ,'sessionIDs.txt'), header=None, squeeze=True)\n",
    "\n",
    "        # add labels\n",
    "        for y in y_fields:\n",
    "            y_data = pd.read_csv(os.path.join(subjectTrainFolderName, 'y_'+ y + '.txt'), names=[y], squeeze=True)\n",
    "            #logging.info(f'{id} - Reading {y} data {y_data.shape}')\n",
    "            data[y] = y_data\n",
    "        train = data[data['sessionID'].str.replace(' ','').isin(sessionIDs_train)]\n",
    "        test = data[data['sessionID'].str.replace(' ','').isin(sessionIDs_test)]\n",
    "            \n",
    "\n",
    "        for labelName in y_fields:\n",
    "            # if all values for the current labels are Nans, continue\n",
    "            if train[labelName].isnull().all():\n",
    "                continue\n",
    "\n",
    "            dfRes = all_results[labelName].loc[id]\n",
    "\n",
    "            dfPred = all_pred[labelName]\n",
    "\n",
    "            bestField = dfRes.index[dfRes.argmin()]\n",
    " \n",
    "            logging.info(f'Seed {seed} Subject {id} Score {labelName} Best method {bestField}')\n",
    "\n",
    "            if bestField == labelName + '_useWholeS':\n",
    "                useFirstHalf = False\n",
    "            else: \n",
    "                useFirstHalf = True\n",
    "                \n",
    "            if bestField == labelName + '_RFregressor':\n",
    "                regressionModel = True\n",
    "            else:\n",
    "                regressionModel = False\n",
    "            \n",
    "            if bestField == labelName + '_kBest50':\n",
    "                selectFeatures = SelectKBest(score_func=f_classif, k=50)\n",
    "            elif bestField == labelName + '_rfFeatueSel':\n",
    "                selectFeatures = SelectFromModel(RandomForestClassifier(random_state = seed))\n",
    "            elif bestField == labelName + '_RFregressor':\n",
    "                selectFeatures = SelectKBest(score_func=f_regression, k=selectKbest)\n",
    "            else:\n",
    "                selectFeatures = SelectKBest(score_func=f_classif, k=selectKbest)\n",
    "                \n",
    "\n",
    "            if bestField == labelName + '_undersample':\n",
    "                fixClassImbalance = 'RandomUnderSampler'\n",
    "            else:\n",
    "                fixClassImbalance = 'none'\n",
    "                \n",
    "            if bestField == labelName + '_bestCombination':\n",
    "                mseNaive = dfRes[labelName+'_naive']\n",
    "                mseBase = dfRes[labelName+'_base']\n",
    "                mseUseWholeS = dfRes[labelName+'_useWholeS']\n",
    "                mseKbest50 = dfRes[labelName+'_kBest50']\n",
    "                mseRfFeatueSel = dfRes[labelName+'_rfFeatureSel']\n",
    "#                 mseSmotenn = dfRes[labelName+'_SMOTENN']\n",
    "                mseUndersample = dfRes[labelName+'_undersample']\n",
    "                mseBestComp = dfRes[labelName+'_bestCombination']\n",
    "                \n",
    "                if (mseBase < mseUseWholeS):\n",
    "                    useFirstHalf = True\n",
    "                else:\n",
    "                    useFirstHalf = False\n",
    "            \n",
    "                minSelFeatScore = min(mseBase, mseKbest50, mseRfFeatueSel)\n",
    "                if minSelFeatScore == mseBase:\n",
    "                    selectFeatures = SelectKBest(score_func=f_classif, k=selectKbest)  #default\n",
    "                elif minSelFeatScore == mseKbest50:\n",
    "                    selectFeatures = SelectKBest(score_func=f_classif, k=50)\n",
    "                elif minSelFeatScore == mseRfFeatueSel:\n",
    "                    selectFeatures = SelectFromModel(RandomForestClassifier(random_state = seed))\n",
    "            \n",
    "                minClassBalScore = min(mseBase, mseUndersample)\n",
    "                if minClassBalScore == mseBase:\n",
    "                    fixClassImbalance = 'none'\n",
    "                elif minClassBalScore == mseUndersample:\n",
    "                    fixClassImbalance = 'RandomUnderSampler'    \n",
    "                \n",
    "\n",
    "            sessionIDs, y_pred = runClassification(train, test, labelName, useFirstHalf, selectFeatures, fixClassImbalance = fixClassImbalance, seed=seed)\n",
    "            # update submission tables with the predictions\n",
    "            for i, sessionID in enumerate(sessionIDs):\n",
    "                sessionID = sessionID.replace(\" \",\"\")\n",
    "                idx = dfPred[dfPred['measurement_id'] == sessionID ].index.tolist()\n",
    "                if len(idx)==0:\n",
    "                    logging.info('session not found in pred matrix' + sessionID)\n",
    "                    continue\n",
    "                dfPred.at[idx[0],'prediction'] = y_pred[i]\n",
    "\n",
    "    # save\n",
    "    for i, labelName in enumerate(y_fields):\n",
    "        fileName = 'BEAT-PD_SC' + str(i+1) + '_'+ labelName + '_'+ str(seed) +'.csv'\n",
    "        logging.info(f'Save file: {fileName}')\n",
    "        dfPred = all_pred[labelName]\n",
    "        dfPred = dfPred.set_index(list(dfPred.columns[[0]]))\n",
    "        dfPred.to_csv(os.path.join(outputFolder, fileName))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['cis', 'real']\n",
    "test_rands = ['S34_K0', 'S34_K1', 'S34_K2', 'S34_K3','S34_K4']\n",
    "dataSetFolderName = os.path.join('..', 'pre_process', 'SegmentedData_winLen500_overlap250_')\n",
    "selectKbest = 100\n",
    "testSize = 0.2\n",
    "y_fields = ['on_off', 'dyskinesia', 'tremor']\n",
    "\n",
    "feature_file = 'X_data_fullFeatures.txt'\n",
    "\n",
    "parallel = True        # Parallel (True) or serial (False) seed procesing\n",
    "nworkers = 10          # Number of parallel workers\n",
    "seeds = range(1,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_rand in test_rands:\n",
    "    outputFolder = os.path.join('features', test_rand)\n",
    "    if not os.path.isdir(outputFolder):\n",
    "        logging.info(f'Making output dir: {outputFolder}')\n",
    "        os.mkdir(outputFolder)\n",
    "\n",
    "    for dataset in datasets:\n",
    "        labels_folder = 'data'\n",
    "\n",
    "        fileName = os.path.join(labels_folder, dataset.upper() + f'-PD_Training_Data_IDs_Labels_{test_rand}.csv')\n",
    "\n",
    "        allSessions_train = pd.read_csv(os.path.join(labels_folder ,dataset.upper() + f'-PD_Training_Data_IDs_Labels_{test_rand}.csv'))\n",
    "        sessionIDs_train = allSessions_train['measurement_id'].to_list()\n",
    "        allSessions_test = pd.read_csv(os.path.join(labels_folder ,dataset.upper() + f'-PD_Test_Data_IDs_Labels_{test_rand}.csv'))\n",
    "        sessionIDs_test = allSessions_test['measurement_id'].to_list()\n",
    "\n",
    "        allSessions = pd.read_csv(fileName)\n",
    "        subject_ids = allSessions['subject_id'].unique()\n",
    "        logging.info(f'Training data: {subject_ids.shape[0]} unique subjects in {allSessions.shape[0]} sessions')    \n",
    "\n",
    "        if parallel:\n",
    "            logging.info(f'Parellel processing of {len(seeds)} seeds using {nworkers} workers')\n",
    "            with Pool(nworkers) as p:\n",
    "                p.map(SessionScoreSeed, seeds)\n",
    "        else:\n",
    "            logging.info(f'Seriel processing of {len(seeds)} seeds')\n",
    "            for seed in seeds:\n",
    "                SessionScoreSeed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
