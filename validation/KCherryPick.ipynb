{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cherry pick\n",
    "Generate the test prediction files using cherry picking from ensembles of feature predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: 2020-05-18 15:16:26,936: Numpy version 1.18.2\n",
      "INFO: 2020-05-18 15:16:27,072: Scipy version 1.4.1\n",
      "INFO: 2020-05-18 15:16:27,166: Pandas version 1.0.3\n",
      "INFO: 2020-05-18 15:16:27,282: Matplotlib version 3.2.0\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(asctime)s: %(message)s')\n",
    "\n",
    "import os\n",
    "import time\n",
    "import getpass\n",
    "\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "logging.info(\"Numpy version \" + np.__version__)\n",
    "import scipy as sp\n",
    "import scipy.signal as sig\n",
    "logging.info(\"Scipy version \" + sp.__version__)\n",
    "import pandas as pd\n",
    "logging.info(\"Pandas version \" + pd.__version__)\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "logging.info(\"Matplotlib version \" + matplotlib.__version__)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# For the standard seed use 34\n",
    "np.random.seed (34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['cis','real']\n",
    "score_names = ['tremor', 'dyskinesia', 'on_off']\n",
    "\n",
    "labels_folder = 'data'\n",
    "Ks = [0,1,2,3,4]\n",
    "test_rand = 'S34_K'\n",
    "\n",
    "dropNaive = True\n",
    "onlyGood = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BEATPD_loss(df, real_score, est_score):\n",
    "        subject_mse = {}\n",
    "        subject_countsq = {}\n",
    "        subject_mul = {}\n",
    "\n",
    "        for subject in subjects[score]:\n",
    "            idx = (df['subject_id']==subject)\n",
    "            if (~df.loc[idx, real_score].isna().all()):\n",
    "                subject_mse[subject] = ((df.loc[idx, real_score]-df.loc[idx, est_score])**2).mean()\n",
    "                subject_countsq[subject] = np.sqrt(idx.sum())\n",
    "                subject_mul[subject] = subject_mse[subject] * subject_countsq[subject]\n",
    "        loss = sum(subject_mul.values()) / sum(subject_countsq.values())\n",
    "        #logging.info(f'BEATPD {loss:.2f}')\n",
    "        return loss\n",
    "\n",
    "def kloss(df, real_score, est_score):\n",
    "        loss = {}\n",
    "        for subject in subjects[score]:\n",
    "            idx = (df['subject_id']==subject)\n",
    "            if (~df.loc[idx, real_score].isna().all()):\n",
    "                loss[subject] = ((df.loc[idx, real_score]-df.loc[idx, est_score])**2).mean()\n",
    "        return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define good and naive subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: 2020-05-18 15:16:37,383: K iterator 0\n",
      "INFO: 2020-05-18 15:16:37,387: Training cis: Read file \"data/CIS-PD_Training_Data_IDs_Labels_S34_K0.csv\" containing 1486 records\n",
      "INFO: 2020-05-18 15:16:37,389: Test cis: Read file \"data/CIS-PD_Test_Data_IDs_Labels_S34_K0.csv\" containing 372 records\n",
      "INFO: 2020-05-18 15:16:37,391: Training real: Read file \"data/REAL-PD_Training_Data_IDs_Labels_S34_K0.csv\" containing 472 records\n",
      "INFO: 2020-05-18 15:16:37,392: Test real: Read file \"data/REAL-PD_Test_Data_IDs_Labels_S34_K0.csv\" containing 119 records\n",
      "INFO: 2020-05-18 15:16:37,399: Score: tremor: unique subjects 19:\n",
      "[1004 1006 1007 1019 1020 1023 1032 1034 1038 1043 1046 1048 1049 'hbv013'\n",
      " 'hbv038' 'hbv023' 'hbv054' 'hbv022' 'hbv012']\n",
      "INFO: 2020-05-18 15:16:37,461: Score: dyskinesia: unique subjects 16:\n",
      "[1004 1007 1019 1023 1034 1038 1039 1043 1044 1048 1049 'hbv013' 'hbv017'\n",
      " 'hbv054' 'hbv018' 'hbv043']\n",
      "INFO: 2020-05-18 15:16:37,513: Score: on_off: unique subjects 22:\n",
      "[1004 1006 1007 1019 1020 1023 1032 1034 1038 1039 1043 1044 1048 1049\n",
      " 1051 'hbv013' 'hbv038' 'hbv051' 'hbv077' 'hbv014' 'hbv043' 'hbv022']\n",
      "INFO: 2020-05-18 15:16:37,577: Score tremor - number of feature files 10\n",
      "INFO: 2020-05-18 15:16:37,614: Score dyskinesia - number of feature files 10\n",
      "INFO: 2020-05-18 15:16:37,651: Score on_off - number of feature files 10\n",
      "INFO: 2020-05-18 15:16:38,990: Negative 212 Positive 144 of 356\n",
      "INFO: 2020-05-18 15:16:38,990: Neg 159 of 212 75.0%\n",
      "INFO: 2020-05-18 15:16:38,991: Pos 82 of 144 56.9%\n",
      "INFO: 2020-05-18 15:16:39,083: Negative 180 Positive 111 of 291\n",
      "INFO: 2020-05-18 15:16:39,084: Neg 136 of 180 75.6%\n",
      "INFO: 2020-05-18 15:16:39,085: Pos 63 of 111 56.8%\n",
      "INFO: 2020-05-18 15:16:39,196: Negative 263 Positive 157 of 420\n",
      "INFO: 2020-05-18 15:16:39,197: Neg 199 of 263 75.7%\n",
      "INFO: 2020-05-18 15:16:39,197: Pos 80 of 157 51.0%\n",
      "INFO: 2020-05-18 15:16:39,219: K iterator 1\n",
      "INFO: 2020-05-18 15:16:39,221: Training cis: Read file \"data/CIS-PD_Training_Data_IDs_Labels_S34_K1.csv\" containing 1486 records\n",
      "INFO: 2020-05-18 15:16:39,223: Test cis: Read file \"data/CIS-PD_Test_Data_IDs_Labels_S34_K1.csv\" containing 372 records\n",
      "INFO: 2020-05-18 15:16:39,225: Training real: Read file \"data/REAL-PD_Training_Data_IDs_Labels_S34_K1.csv\" containing 473 records\n",
      "INFO: 2020-05-18 15:16:39,227: Test real: Read file \"data/REAL-PD_Test_Data_IDs_Labels_S34_K1.csv\" containing 118 records\n",
      "INFO: 2020-05-18 15:16:39,233: Score: tremor: unique subjects 19:\n",
      "[1004 1006 1007 1019 1020 1023 1032 1034 1038 1043 1046 1048 1049 'hbv013'\n",
      " 'hbv038' 'hbv023' 'hbv054' 'hbv022' 'hbv012']\n",
      "INFO: 2020-05-18 15:16:39,298: Score: dyskinesia: unique subjects 16:\n",
      "[1004 1007 1019 1023 1034 1038 1039 1043 1044 1048 1049 'hbv013' 'hbv017'\n",
      " 'hbv054' 'hbv018' 'hbv043']\n",
      "INFO: 2020-05-18 15:16:39,350: Score: on_off: unique subjects 22:\n",
      "[1004 1006 1007 1019 1020 1023 1032 1034 1038 1039 1043 1044 1048 1049\n",
      " 1051 'hbv013' 'hbv038' 'hbv051' 'hbv077' 'hbv014' 'hbv043' 'hbv022']\n",
      "INFO: 2020-05-18 15:16:39,415: Score tremor - number of feature files 10\n",
      "INFO: 2020-05-18 15:16:39,452: Score dyskinesia - number of feature files 10\n",
      "INFO: 2020-05-18 15:16:39,488: Score on_off - number of feature files 10\n",
      "INFO: 2020-05-18 15:16:40,847: Negative 200 Positive 157 of 357\n",
      "INFO: 2020-05-18 15:16:40,847: Neg 141 of 200 70.5%\n",
      "INFO: 2020-05-18 15:16:40,848: Pos 75 of 157 47.8%\n",
      "INFO: 2020-05-18 15:16:40,937: Negative 176 Positive 113 of 289\n",
      "INFO: 2020-05-18 15:16:40,938: Neg 136 of 176 77.3%\n",
      "INFO: 2020-05-18 15:16:40,939: Pos 64 of 113 56.6%\n",
      "INFO: 2020-05-18 15:16:41,050: Negative 266 Positive 153 of 419\n",
      "INFO: 2020-05-18 15:16:41,051: Neg 175 of 266 65.8%\n",
      "INFO: 2020-05-18 15:16:41,052: Pos 83 of 153 54.2%\n",
      "INFO: 2020-05-18 15:16:41,073: K iterator 2\n",
      "INFO: 2020-05-18 15:16:41,076: Training cis: Read file \"data/CIS-PD_Training_Data_IDs_Labels_S34_K2.csv\" containing 1486 records\n",
      "INFO: 2020-05-18 15:16:41,078: Test cis: Read file \"data/CIS-PD_Test_Data_IDs_Labels_S34_K2.csv\" containing 372 records\n",
      "INFO: 2020-05-18 15:16:41,079: Training real: Read file \"data/REAL-PD_Training_Data_IDs_Labels_S34_K2.csv\" containing 473 records\n",
      "INFO: 2020-05-18 15:16:41,081: Test real: Read file \"data/REAL-PD_Test_Data_IDs_Labels_S34_K2.csv\" containing 118 records\n",
      "INFO: 2020-05-18 15:16:41,087: Score: tremor: unique subjects 19:\n",
      "[1004 1006 1007 1019 1020 1023 1032 1034 1038 1043 1046 1048 1049 'hbv013'\n",
      " 'hbv038' 'hbv023' 'hbv054' 'hbv022' 'hbv012']\n",
      "INFO: 2020-05-18 15:16:41,148: Score: dyskinesia: unique subjects 16:\n",
      "[1004 1007 1019 1023 1034 1038 1039 1043 1044 1048 1049 'hbv013' 'hbv017'\n",
      " 'hbv054' 'hbv018' 'hbv043']\n",
      "INFO: 2020-05-18 15:16:41,201: Score: on_off: unique subjects 22:\n",
      "[1004 1006 1007 1019 1020 1023 1032 1034 1038 1039 1043 1044 1048 1049\n",
      " 1051 'hbv013' 'hbv038' 'hbv051' 'hbv077' 'hbv014' 'hbv043' 'hbv022']\n",
      "INFO: 2020-05-18 15:16:41,265: Score tremor - number of feature files 10\n",
      "INFO: 2020-05-18 15:16:41,302: Score dyskinesia - number of feature files 10\n",
      "INFO: 2020-05-18 15:16:41,339: Score on_off - number of feature files 10\n",
      "INFO: 2020-05-18 15:16:42,673: Negative 214 Positive 140 of 354\n",
      "INFO: 2020-05-18 15:16:42,673: Neg 157 of 214 73.4%\n",
      "INFO: 2020-05-18 15:16:42,674: Pos 66 of 140 47.1%\n",
      "INFO: 2020-05-18 15:16:42,765: Negative 183 Positive 108 of 291\n",
      "INFO: 2020-05-18 15:16:42,766: Neg 136 of 183 74.3%\n",
      "INFO: 2020-05-18 15:16:42,767: Pos 63 of 108 58.3%\n",
      "INFO: 2020-05-18 15:16:42,879: Negative 258 Positive 160 of 418\n",
      "INFO: 2020-05-18 15:16:42,880: Neg 189 of 258 73.3%\n",
      "INFO: 2020-05-18 15:16:42,881: Pos 77 of 160 48.1%\n",
      "INFO: 2020-05-18 15:16:42,903: K iterator 3\n",
      "INFO: 2020-05-18 15:16:42,905: Training cis: Read file \"data/CIS-PD_Training_Data_IDs_Labels_S34_K3.csv\" containing 1487 records\n",
      "INFO: 2020-05-18 15:16:42,907: Test cis: Read file \"data/CIS-PD_Test_Data_IDs_Labels_S34_K3.csv\" containing 371 records\n",
      "INFO: 2020-05-18 15:16:42,909: Training real: Read file \"data/REAL-PD_Training_Data_IDs_Labels_S34_K3.csv\" containing 473 records\n",
      "INFO: 2020-05-18 15:16:42,910: Test real: Read file \"data/REAL-PD_Test_Data_IDs_Labels_S34_K3.csv\" containing 118 records\n",
      "INFO: 2020-05-18 15:16:42,917: Score: tremor: unique subjects 19:\n",
      "[1004 1006 1007 1019 1020 1023 1032 1034 1038 1043 1046 1048 1049 'hbv013'\n",
      " 'hbv038' 'hbv023' 'hbv054' 'hbv022' 'hbv012']\n",
      "INFO: 2020-05-18 15:16:42,977: Score: dyskinesia: unique subjects 16:\n",
      "[1004 1007 1019 1023 1034 1038 1039 1043 1044 1048 1049 'hbv013' 'hbv017'\n",
      " 'hbv054' 'hbv018' 'hbv043']\n",
      "INFO: 2020-05-18 15:16:43,029: Score: on_off: unique subjects 22:\n",
      "[1004 1006 1007 1019 1020 1023 1032 1034 1038 1039 1043 1044 1048 1049\n",
      " 1051 'hbv013' 'hbv038' 'hbv051' 'hbv077' 'hbv014' 'hbv043' 'hbv022']\n",
      "INFO: 2020-05-18 15:16:43,093: Score tremor - number of feature files 6\n",
      "INFO: 2020-05-18 15:16:43,117: Score dyskinesia - number of feature files 6\n",
      "INFO: 2020-05-18 15:16:43,139: Score on_off - number of feature files 6\n",
      "INFO: 2020-05-18 15:16:43,982: Negative 168 Positive 136 of 354\n",
      "INFO: 2020-05-18 15:16:43,983: Neg 116 of 168 69.0%\n",
      "INFO: 2020-05-18 15:16:43,984: Pos 62 of 136 45.6%\n",
      "INFO: 2020-05-18 15:16:44,081: Negative 145 Positive 93 of 288\n",
      "INFO: 2020-05-18 15:16:44,082: Neg 119 of 145 82.1%\n",
      "INFO: 2020-05-18 15:16:44,083: Pos 37 of 93 39.8%\n",
      "INFO: 2020-05-18 15:16:44,198: Negative 223 Positive 154 of 423\n",
      "INFO: 2020-05-18 15:16:44,199: Neg 162 of 223 72.6%\n",
      "INFO: 2020-05-18 15:16:44,200: Pos 79 of 154 51.3%\n"
     ]
    }
   ],
   "source": [
    "parms  = { }\n",
    "for K in Ks:\n",
    "    parms [K] = {}\n",
    "    \n",
    "    logging.info(f'K iterator {K}')\n",
    "    training_labels, test_labels, test_data_folder = {}, {}, {}\n",
    "     \n",
    "    for dataset in datasets:\n",
    "        test_label_file = os.path.join(labels_folder, dataset.upper()+f'-PD_Test_Data_IDs_Labels_{test_rand}{K}.csv')\n",
    "        training_label_file = os.path.join(labels_folder, dataset.upper()+f'-PD_Training_Data_IDs_Labels_{test_rand}{K}.csv')\n",
    "\n",
    "        training_labels[dataset] = pd.read_csv(training_label_file)\n",
    "        logging.info(f'Training {dataset}: Read file \"{training_label_file}\" containing {training_labels[dataset].shape[0]} records')\n",
    "\n",
    "        test_labels[dataset] = pd.read_csv(test_label_file)\n",
    "        logging.info(f'Test {dataset}: Read file \"{test_label_file}\" containing {test_labels[dataset].shape[0]} records')\n",
    "        \n",
    "    train_df, test_df = {}, {}\n",
    "    subjects, test_subject_sq = {}, {}\n",
    "    for score in score_names:\n",
    "        field_cols = ['measurement_id', 'subject_id', score]\n",
    "        train_df[score] = pd.concat([training_labels['cis'][field_cols], training_labels['real'][field_cols]]).dropna(subset=[score])\n",
    "        test_df[score] = pd.concat([test_labels['cis'][field_cols], test_labels['real'][field_cols]]).dropna(subset=[score])\n",
    "        subjects[score] = train_df[score]['subject_id'].unique()\n",
    "        logging.info(f'Score: {score}: unique subjects {subjects[score].shape[0]}:\\n{subjects[score]}')\n",
    "        test_subject_sq[score] = [np.sqrt((test_df[score]['subject_id']==subject).sum()) for subject in subjects]\n",
    "        for subject in subjects[score]:\n",
    "            test_df[score].loc[test_df[score]['subject_id']==subject, 'naive_mean'] = train_df[score][train_df[score]['subject_id']==subject][score].mean()\n",
    "            test_df[score].loc[test_df[score]['subject_id']==subject, 'naive_std'] = train_df[score][train_df[score]['subject_id']==subject][score].std()\n",
    "        test_df[score].set_index('measurement_id', inplace=True)\n",
    "\n",
    "    for score in score_names:        \n",
    "        feature_results = sorted(glob.glob(f'features/{test_rand}{K}/*{score}_*.csv'))\n",
    "        logging.info(f'Score {score} - number of feature files {len(feature_results)}')\n",
    "        for i, file_name in enumerate(feature_results):\n",
    "            d = pd.read_csv(file_name).set_index('measurement_id')\n",
    "            test_df[score][f'f{i}'] = d['prediction']\n",
    "            idx = test_df[score][f'f{i}'].isna() & ~test_df[score]['naive_mean'].isna()\n",
    "            test_df[score].loc[idx,f'f{i}'] = test_df[score].loc[idx,'naive_mean']      \n",
    "\n",
    "    ### Generate a single dataframe\n",
    "\n",
    "    for j, score in enumerate(score_names):\n",
    "        feature_cols = test_df[score].filter(regex='^f')\n",
    "        test_df[score]['f_mean'] = feature_cols.mean(axis=1)\n",
    "        test_df[score]['f_std'] = feature_cols.std(axis=1)\n",
    "        test_df[score]['f_median'] = feature_cols.median(axis=1)\n",
    "        for i, subject in enumerate(subjects[score]):\n",
    "            for feature_col in feature_cols:\n",
    "                test_df[score].loc[test_df[score]['subject_id']==subject,'a'+feature_col[1:]] = (\n",
    "                    test_df[score].loc[test_df[score]['subject_id']==subject, feature_col] - \n",
    "                    test_df[score].loc[test_df[score]['subject_id']==subject, feature_col].mean() +\n",
    "                    test_df[score].loc[test_df[score]['subject_id']==subject, 'naive_mean'].mean() )\n",
    "\n",
    "        adjusted_cols = test_df[score].filter(regex='^a')\n",
    "        test_df[score]['a_mean'] = adjusted_cols.mean(axis=1)\n",
    "        test_df[score]['a_std'] = adjusted_cols.std(axis=1)\n",
    "        test_df[score]['a_median'] = adjusted_cols.median(axis=1)\n",
    "\n",
    "    score_df = pd.DataFrame()\n",
    "    for score in score_names:\n",
    "        score_df.loc['naive', score] = BEATPD_loss(test_df[score],score,'naive_mean')\n",
    "        score_df.loc['f_mean', score] = BEATPD_loss(test_df[score],score,'f_mean')\n",
    "        score_df.loc['a_mean', score] = BEATPD_loss(test_df[score],score,'a_mean')\n",
    "        \n",
    "        parms[K][(score, 'score', 'naive')] = kloss(test_df[score],score,'naive_mean')\n",
    "        parms[K][(score, 'score', 'ayala')] = kloss(test_df[score],score,'a_mean')\n",
    "\n",
    "        negfactor=0\n",
    "        posfactor=0\n",
    "        sneg=test_df[score][(test_df[score]['a_mean']+negfactor*test_df[score]['a_std']<test_df[score]['naive_mean'])  ]\n",
    "        spos=test_df[score][(test_df[score]['a_mean']-posfactor*test_df[score]['a_std']>test_df[score]['naive_mean'])  ]        \n",
    "\n",
    "        logging.info(f'Negative {sneg.shape[0]} Positive {spos.shape[0]} of {test_df[score].shape[0]}')\n",
    "        logging.info(f\"Neg {(sneg[score]<sneg['naive_mean']).sum()} of {sneg.shape[0]} {100*(sneg[score]<sneg['naive_mean']).sum()/sneg.shape[0]:.1f}%\")\n",
    "        logging.info(f\"Pos {(spos[score]>spos['naive_mean']).sum()} of {spos.shape[0]} {100*(spos[score]>spos['naive_mean']).sum()/spos.shape[0]:.1f}%\")\n",
    "        test_df[score]['cherry'] = test_df[score]['naive_mean']\n",
    "        #test_df[score].loc[sneg.index, 'cherry'] = sneg['a_mean'] + (sneg['a_mean']-sneg['naive_mean']) * 0.5\n",
    "        #test_df[score].loc[spos.index, 'cherry'] = spos['a_mean'] + (spos['a_mean']-spos['naive_mean']) * 0.5\n",
    "        test_df[score].loc[sneg.index, 'cherry'] = sneg['a_mean'] \n",
    "        test_df[score].loc[spos.index, 'cherry'] = spos['a_mean'] \n",
    "        score_df.loc['cherry', score] = BEATPD_loss(test_df[score],score,'cherry')\n",
    "    parms[K]['score'] = score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = list(training_labels['cis']['subject_id'].unique()) + list(training_labels['real']['subject_id'].unique())\n",
    "da = pd.DataFrame(index=sss)\n",
    "good_df = pd.DataFrame()\n",
    "naive_df = pd.DataFrame()\n",
    "for score in score_names:\n",
    "    for K in Ks:\n",
    "        da[score+str(K)] = pd.Series(parms[K][(score,'score','naive')]) - pd.Series(parms[K][(score,'score','ayala')])  \n",
    "    dd = da.filter(regex=f'{score}')\n",
    "    good_df[score] = dd.mean(axis=1)>0.0\n",
    "    naive_df[score] = dd.mean(axis=1)<0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tremor\n",
      "Index([1007, 1023, 1034, 1046, 1048, 'hbv054', 'hbv012'], dtype='object')\n",
      "dyskinesia\n",
      "Index([1007, 1023, 1034, 1043, 1044, 1048, 'hbv054', 'hbv018'], dtype='object')\n",
      "on_off\n",
      "Index([1006, 1044, 'hbv013', 'hbv051', 'hbv077', 'hbv043'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "for score in score_names:\n",
    "    print(score)\n",
    "    print(naive_df[naive_df[score]].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tremor0</th>\n",
       "      <th>tremor1</th>\n",
       "      <th>tremor2</th>\n",
       "      <th>tremor3</th>\n",
       "      <th>dyskinesia0</th>\n",
       "      <th>dyskinesia1</th>\n",
       "      <th>dyskinesia2</th>\n",
       "      <th>dyskinesia3</th>\n",
       "      <th>on_off0</th>\n",
       "      <th>on_off1</th>\n",
       "      <th>on_off2</th>\n",
       "      <th>on_off3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>0.052470</td>\n",
       "      <td>0.407035</td>\n",
       "      <td>0.232054</td>\n",
       "      <td>5.099222e-01</td>\n",
       "      <td>0.040748</td>\n",
       "      <td>0.192830</td>\n",
       "      <td>0.343903</td>\n",
       "      <td>0.426991</td>\n",
       "      <td>-0.022416</td>\n",
       "      <td>0.264478</td>\n",
       "      <td>0.321505</td>\n",
       "      <td>3.934834e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>-0.020648</td>\n",
       "      <td>0.036357</td>\n",
       "      <td>-0.083122</td>\n",
       "      <td>8.341722e-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015756</td>\n",
       "      <td>0.005744</td>\n",
       "      <td>-0.045952</td>\n",
       "      <td>-7.995845e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>0.012604</td>\n",
       "      <td>-0.002898</td>\n",
       "      <td>-0.021760</td>\n",
       "      <td>-1.350119e-03</td>\n",
       "      <td>-0.001546</td>\n",
       "      <td>-0.000776</td>\n",
       "      <td>-0.000652</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.149825</td>\n",
       "      <td>0.025629</td>\n",
       "      <td>0.088554</td>\n",
       "      <td>-1.051866e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>0.233259</td>\n",
       "      <td>-0.045032</td>\n",
       "      <td>0.089754</td>\n",
       "      <td>-1.213671e-01</td>\n",
       "      <td>0.421769</td>\n",
       "      <td>0.068614</td>\n",
       "      <td>0.210575</td>\n",
       "      <td>-0.153097</td>\n",
       "      <td>0.567448</td>\n",
       "      <td>0.100092</td>\n",
       "      <td>0.268251</td>\n",
       "      <td>4.578736e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>0.013509</td>\n",
       "      <td>0.022539</td>\n",
       "      <td>0.031801</td>\n",
       "      <td>-2.546523e-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.042677</td>\n",
       "      <td>0.014205</td>\n",
       "      <td>0.021498</td>\n",
       "      <td>3.199716e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>0.011125</td>\n",
       "      <td>-0.002729</td>\n",
       "      <td>-0.061053</td>\n",
       "      <td>-2.185325e-02</td>\n",
       "      <td>-0.016623</td>\n",
       "      <td>-0.107225</td>\n",
       "      <td>-0.065756</td>\n",
       "      <td>-0.252136</td>\n",
       "      <td>-0.036632</td>\n",
       "      <td>0.066628</td>\n",
       "      <td>-0.096171</td>\n",
       "      <td>2.661924e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>-0.015115</td>\n",
       "      <td>0.037728</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>3.699515e-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.024152</td>\n",
       "      <td>0.027688</td>\n",
       "      <td>0.075018</td>\n",
       "      <td>8.264846e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>-0.035379</td>\n",
       "      <td>-0.061622</td>\n",
       "      <td>0.029295</td>\n",
       "      <td>2.172455e-02</td>\n",
       "      <td>-0.047012</td>\n",
       "      <td>-0.012737</td>\n",
       "      <td>-0.079134</td>\n",
       "      <td>-0.042991</td>\n",
       "      <td>0.240171</td>\n",
       "      <td>0.398008</td>\n",
       "      <td>0.075692</td>\n",
       "      <td>-1.143865e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>0.039815</td>\n",
       "      <td>-0.038332</td>\n",
       "      <td>-0.024963</td>\n",
       "      <td>3.651111e-02</td>\n",
       "      <td>0.043232</td>\n",
       "      <td>0.074147</td>\n",
       "      <td>0.009916</td>\n",
       "      <td>0.124211</td>\n",
       "      <td>0.304885</td>\n",
       "      <td>-0.277110</td>\n",
       "      <td>0.242414</td>\n",
       "      <td>5.729182e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.083635</td>\n",
       "      <td>0.151420</td>\n",
       "      <td>0.043571</td>\n",
       "      <td>0.098651</td>\n",
       "      <td>0.028309</td>\n",
       "      <td>0.303863</td>\n",
       "      <td>0.058165</td>\n",
       "      <td>1.714582e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>0.302404</td>\n",
       "      <td>-0.158173</td>\n",
       "      <td>0.707608</td>\n",
       "      <td>-3.956667e-01</td>\n",
       "      <td>-0.078847</td>\n",
       "      <td>-0.117671</td>\n",
       "      <td>0.074555</td>\n",
       "      <td>-0.007563</td>\n",
       "      <td>0.320646</td>\n",
       "      <td>-0.162994</td>\n",
       "      <td>0.326336</td>\n",
       "      <td>-1.628003e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000134</td>\n",
       "      <td>0.004968</td>\n",
       "      <td>-0.011636</td>\n",
       "      <td>-0.002533</td>\n",
       "      <td>-0.106430</td>\n",
       "      <td>-0.062116</td>\n",
       "      <td>-0.030218</td>\n",
       "      <td>1.712539e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046</th>\n",
       "      <td>0.007198</td>\n",
       "      <td>-0.075019</td>\n",
       "      <td>-0.046742</td>\n",
       "      <td>2.098644e-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048</th>\n",
       "      <td>-0.016640</td>\n",
       "      <td>-0.004769</td>\n",
       "      <td>0.034342</td>\n",
       "      <td>-4.316469e-02</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>-0.026465</td>\n",
       "      <td>-0.000653</td>\n",
       "      <td>-0.042949</td>\n",
       "      <td>0.047473</td>\n",
       "      <td>0.081183</td>\n",
       "      <td>0.137119</td>\n",
       "      <td>1.777789e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>0.273512</td>\n",
       "      <td>0.142691</td>\n",
       "      <td>0.061778</td>\n",
       "      <td>1.786991e-01</td>\n",
       "      <td>-0.018874</td>\n",
       "      <td>0.041338</td>\n",
       "      <td>0.005575</td>\n",
       "      <td>-0.005819</td>\n",
       "      <td>0.322291</td>\n",
       "      <td>0.059121</td>\n",
       "      <td>0.014342</td>\n",
       "      <td>1.144427e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.082302</td>\n",
       "      <td>-0.141512</td>\n",
       "      <td>0.033102</td>\n",
       "      <td>4.420386e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hbv013</th>\n",
       "      <td>-0.105555</td>\n",
       "      <td>0.234599</td>\n",
       "      <td>-0.019312</td>\n",
       "      <td>8.326673e-17</td>\n",
       "      <td>0.005783</td>\n",
       "      <td>0.035528</td>\n",
       "      <td>0.025057</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006856</td>\n",
       "      <td>0.040146</td>\n",
       "      <td>-0.110160</td>\n",
       "      <td>2.775558e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hbv038</th>\n",
       "      <td>0.073971</td>\n",
       "      <td>0.060535</td>\n",
       "      <td>-0.043371</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.044326</td>\n",
       "      <td>0.064198</td>\n",
       "      <td>-0.072711</td>\n",
       "      <td>1.110223e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hbv017</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016800</td>\n",
       "      <td>-0.001618</td>\n",
       "      <td>0.035157</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hbv023</th>\n",
       "      <td>-0.061529</td>\n",
       "      <td>-0.004775</td>\n",
       "      <td>0.118963</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hbv051</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.036384</td>\n",
       "      <td>-0.038932</td>\n",
       "      <td>-0.007837</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hbv077</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.007824</td>\n",
       "      <td>0.028281</td>\n",
       "      <td>-0.054870</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hbv054</th>\n",
       "      <td>-0.005489</td>\n",
       "      <td>-0.006036</td>\n",
       "      <td>-0.031731</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>-0.035069</td>\n",
       "      <td>-0.048587</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hbv014</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.033525</td>\n",
       "      <td>-0.033430</td>\n",
       "      <td>0.065396</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hbv018</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.005336</td>\n",
       "      <td>-0.117287</td>\n",
       "      <td>-0.118660</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hbv043</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.020511</td>\n",
       "      <td>0.077772</td>\n",
       "      <td>-0.054557</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005102</td>\n",
       "      <td>-0.202006</td>\n",
       "      <td>-0.033338</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hbv022</th>\n",
       "      <td>0.263034</td>\n",
       "      <td>0.247523</td>\n",
       "      <td>-0.059455</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.010694</td>\n",
       "      <td>0.012957</td>\n",
       "      <td>0.002145</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hbv012</th>\n",
       "      <td>-0.508304</td>\n",
       "      <td>0.094620</td>\n",
       "      <td>-0.009926</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         tremor0   tremor1   tremor2       tremor3  dyskinesia0  dyskinesia1  \\\n",
       "1004    0.052470  0.407035  0.232054  5.099222e-01     0.040748     0.192830   \n",
       "1006   -0.020648  0.036357 -0.083122  8.341722e-02          NaN          NaN   \n",
       "1007    0.012604 -0.002898 -0.021760 -1.350119e-03    -0.001546    -0.000776   \n",
       "1019    0.233259 -0.045032  0.089754 -1.213671e-01     0.421769     0.068614   \n",
       "1020    0.013509  0.022539  0.031801 -2.546523e-03          NaN          NaN   \n",
       "1023    0.011125 -0.002729 -0.061053 -2.185325e-02    -0.016623    -0.107225   \n",
       "1032   -0.015115  0.037728  0.009200  3.699515e-02          NaN          NaN   \n",
       "1034   -0.035379 -0.061622  0.029295  2.172455e-02    -0.047012    -0.012737   \n",
       "1038    0.039815 -0.038332 -0.024963  3.651111e-02     0.043232     0.074147   \n",
       "1039         NaN       NaN       NaN           NaN     0.083635     0.151420   \n",
       "1043    0.302404 -0.158173  0.707608 -3.956667e-01    -0.078847    -0.117671   \n",
       "1044         NaN       NaN       NaN           NaN    -0.000134     0.004968   \n",
       "1046    0.007198 -0.075019 -0.046742  2.098644e-02          NaN          NaN   \n",
       "1048   -0.016640 -0.004769  0.034342 -4.316469e-02     0.000852    -0.026465   \n",
       "1049    0.273512  0.142691  0.061778  1.786991e-01    -0.018874     0.041338   \n",
       "1051         NaN       NaN       NaN           NaN          NaN          NaN   \n",
       "hbv013 -0.105555  0.234599 -0.019312  8.326673e-17     0.005783     0.035528   \n",
       "hbv038  0.073971  0.060535 -0.043371  0.000000e+00          NaN          NaN   \n",
       "hbv017       NaN       NaN       NaN           NaN     0.016800    -0.001618   \n",
       "hbv023 -0.061529 -0.004775  0.118963  0.000000e+00          NaN          NaN   \n",
       "hbv051       NaN       NaN       NaN           NaN          NaN          NaN   \n",
       "hbv077       NaN       NaN       NaN           NaN          NaN          NaN   \n",
       "hbv054 -0.005489 -0.006036 -0.031731  0.000000e+00     0.001333    -0.035069   \n",
       "hbv014       NaN       NaN       NaN           NaN          NaN          NaN   \n",
       "hbv018       NaN       NaN       NaN           NaN    -0.005336    -0.117287   \n",
       "hbv043       NaN       NaN       NaN           NaN    -0.020511     0.077772   \n",
       "hbv022  0.263034  0.247523 -0.059455  0.000000e+00          NaN          NaN   \n",
       "hbv012 -0.508304  0.094620 -0.009926  0.000000e+00          NaN          NaN   \n",
       "\n",
       "        dyskinesia2  dyskinesia3   on_off0   on_off1   on_off2       on_off3  \n",
       "1004       0.343903     0.426991 -0.022416  0.264478  0.321505  3.934834e-01  \n",
       "1006            NaN          NaN  0.015756  0.005744 -0.045952 -7.995845e-03  \n",
       "1007      -0.000652     0.000244  0.149825  0.025629  0.088554 -1.051866e-02  \n",
       "1019       0.210575    -0.153097  0.567448  0.100092  0.268251  4.578736e-02  \n",
       "1020            NaN          NaN  0.042677  0.014205  0.021498  3.199716e-03  \n",
       "1023      -0.065756    -0.252136 -0.036632  0.066628 -0.096171  2.661924e-01  \n",
       "1032            NaN          NaN -0.024152  0.027688  0.075018  8.264846e-02  \n",
       "1034      -0.079134    -0.042991  0.240171  0.398008  0.075692 -1.143865e-01  \n",
       "1038       0.009916     0.124211  0.304885 -0.277110  0.242414  5.729182e-01  \n",
       "1039       0.043571     0.098651  0.028309  0.303863  0.058165  1.714582e-01  \n",
       "1043       0.074555    -0.007563  0.320646 -0.162994  0.326336 -1.628003e-01  \n",
       "1044      -0.011636    -0.002533 -0.106430 -0.062116 -0.030218  1.712539e-03  \n",
       "1046            NaN          NaN       NaN       NaN       NaN           NaN  \n",
       "1048      -0.000653    -0.042949  0.047473  0.081183  0.137119  1.777789e-01  \n",
       "1049       0.005575    -0.005819  0.322291  0.059121  0.014342  1.144427e-01  \n",
       "1051            NaN          NaN  0.082302 -0.141512  0.033102  4.420386e-02  \n",
       "hbv013     0.025057     0.000000  0.006856  0.040146 -0.110160  2.775558e-17  \n",
       "hbv038          NaN          NaN  0.044326  0.064198 -0.072711  1.110223e-16  \n",
       "hbv017     0.035157     0.000000       NaN       NaN       NaN           NaN  \n",
       "hbv023          NaN          NaN       NaN       NaN       NaN           NaN  \n",
       "hbv051          NaN          NaN -0.036384 -0.038932 -0.007837  0.000000e+00  \n",
       "hbv077          NaN          NaN -0.007824  0.028281 -0.054870  0.000000e+00  \n",
       "hbv054    -0.048587     0.000000       NaN       NaN       NaN           NaN  \n",
       "hbv014          NaN          NaN  0.033525 -0.033430  0.065396  0.000000e+00  \n",
       "hbv018    -0.118660     0.000000       NaN       NaN       NaN           NaN  \n",
       "hbv043    -0.054557     0.000000  0.005102 -0.202006 -0.033338  0.000000e+00  \n",
       "hbv022          NaN          NaN -0.010694  0.012957  0.002145  0.000000e+00  \n",
       "hbv012          NaN          NaN       NaN       NaN       NaN           NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read label files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: 2020-05-18 15:16:51,185: K iterator 0\n",
      "INFO: 2020-05-18 15:16:51,188: Training cis: Read file \"data/CIS-PD_Training_Data_IDs_Labels_S34_K0.csv\" containing 1486 records\n",
      "INFO: 2020-05-18 15:16:51,190: Test cis: Read file \"data/CIS-PD_Test_Data_IDs_Labels_S34_K0.csv\" containing 372 records\n",
      "INFO: 2020-05-18 15:16:51,191: Training real: Read file \"data/REAL-PD_Training_Data_IDs_Labels_S34_K0.csv\" containing 472 records\n",
      "INFO: 2020-05-18 15:16:51,193: Test real: Read file \"data/REAL-PD_Test_Data_IDs_Labels_S34_K0.csv\" containing 119 records\n",
      "INFO: 2020-05-18 15:16:51,200: Score: tremor: unique subjects 19:\n",
      "[1004 1006 1007 1019 1020 1023 1032 1034 1038 1043 1046 1048 1049 'hbv013'\n",
      " 'hbv038' 'hbv023' 'hbv054' 'hbv022' 'hbv012']\n",
      "INFO: 2020-05-18 15:16:51,260: Score: dyskinesia: unique subjects 16:\n",
      "[1004 1007 1019 1023 1034 1038 1039 1043 1044 1048 1049 'hbv013' 'hbv017'\n",
      " 'hbv054' 'hbv018' 'hbv043']\n",
      "INFO: 2020-05-18 15:16:51,312: Score: on_off: unique subjects 22:\n",
      "[1004 1006 1007 1019 1020 1023 1032 1034 1038 1039 1043 1044 1048 1049\n",
      " 1051 'hbv013' 'hbv038' 'hbv051' 'hbv077' 'hbv014' 'hbv043' 'hbv022']\n",
      "INFO: 2020-05-18 15:16:51,376: Score tremor - number of feature files 10\n",
      "INFO: 2020-05-18 15:16:51,413: Score dyskinesia - number of feature files 10\n",
      "INFO: 2020-05-18 15:16:51,449: Score on_off - number of feature files 10\n",
      "INFO: 2020-05-18 15:16:52,795: Negative 128 Positive 86 of 356\n",
      "INFO: 2020-05-18 15:16:52,796: Neg 102 of 128 79.7%\n",
      "INFO: 2020-05-18 15:16:52,797: Pos 52 of 86 60.5%\n",
      "INFO: 2020-05-18 15:16:52,891: Negative 80 Positive 65 of 291\n",
      "INFO: 2020-05-18 15:16:52,891: Neg 56 of 80 70.0%\n",
      "INFO: 2020-05-18 15:16:52,892: Pos 44 of 65 67.7%\n",
      "INFO: 2020-05-18 15:16:53,012: Negative 229 Positive 133 of 420\n",
      "INFO: 2020-05-18 15:16:53,013: Neg 177 of 229 77.3%\n",
      "INFO: 2020-05-18 15:16:53,013: Pos 69 of 133 51.9%\n",
      "INFO: 2020-05-18 15:16:53,035: K iterator 1\n",
      "INFO: 2020-05-18 15:16:53,038: Training cis: Read file \"data/CIS-PD_Training_Data_IDs_Labels_S34_K1.csv\" containing 1486 records\n",
      "INFO: 2020-05-18 15:16:53,040: Test cis: Read file \"data/CIS-PD_Test_Data_IDs_Labels_S34_K1.csv\" containing 372 records\n",
      "INFO: 2020-05-18 15:16:53,041: Training real: Read file \"data/REAL-PD_Training_Data_IDs_Labels_S34_K1.csv\" containing 473 records\n",
      "INFO: 2020-05-18 15:16:53,043: Test real: Read file \"data/REAL-PD_Test_Data_IDs_Labels_S34_K1.csv\" containing 118 records\n",
      "INFO: 2020-05-18 15:16:53,049: Score: tremor: unique subjects 19:\n",
      "[1004 1006 1007 1019 1020 1023 1032 1034 1038 1043 1046 1048 1049 'hbv013'\n",
      " 'hbv038' 'hbv023' 'hbv054' 'hbv022' 'hbv012']\n",
      "INFO: 2020-05-18 15:16:53,111: Score: dyskinesia: unique subjects 16:\n",
      "[1004 1007 1019 1023 1034 1038 1039 1043 1044 1048 1049 'hbv013' 'hbv017'\n",
      " 'hbv054' 'hbv018' 'hbv043']\n",
      "INFO: 2020-05-18 15:16:53,164: Score: on_off: unique subjects 22:\n",
      "[1004 1006 1007 1019 1020 1023 1032 1034 1038 1039 1043 1044 1048 1049\n",
      " 1051 'hbv013' 'hbv038' 'hbv051' 'hbv077' 'hbv014' 'hbv043' 'hbv022']\n",
      "INFO: 2020-05-18 15:16:53,228: Score tremor - number of feature files 10\n",
      "INFO: 2020-05-18 15:16:53,265: Score dyskinesia - number of feature files 10\n",
      "INFO: 2020-05-18 15:16:53,302: Score on_off - number of feature files 10\n",
      "INFO: 2020-05-18 15:16:54,651: Negative 117 Positive 99 of 357\n",
      "INFO: 2020-05-18 15:16:54,652: Neg 84 of 117 71.8%\n",
      "INFO: 2020-05-18 15:16:54,652: Pos 45 of 99 45.5%\n",
      "INFO: 2020-05-18 15:16:54,742: Negative 72 Positive 70 of 289\n",
      "INFO: 2020-05-18 15:16:54,743: Neg 54 of 72 75.0%\n",
      "INFO: 2020-05-18 15:16:54,744: Pos 50 of 70 71.4%\n",
      "INFO: 2020-05-18 15:16:54,864: Negative 230 Positive 131 of 419\n",
      "INFO: 2020-05-18 15:16:54,865: Neg 156 of 230 67.8%\n",
      "INFO: 2020-05-18 15:16:54,865: Pos 74 of 131 56.5%\n",
      "INFO: 2020-05-18 15:16:54,887: K iterator 2\n",
      "INFO: 2020-05-18 15:16:54,890: Training cis: Read file \"data/CIS-PD_Training_Data_IDs_Labels_S34_K2.csv\" containing 1486 records\n",
      "INFO: 2020-05-18 15:16:54,892: Test cis: Read file \"data/CIS-PD_Test_Data_IDs_Labels_S34_K2.csv\" containing 372 records\n",
      "INFO: 2020-05-18 15:16:54,893: Training real: Read file \"data/REAL-PD_Training_Data_IDs_Labels_S34_K2.csv\" containing 473 records\n",
      "INFO: 2020-05-18 15:16:54,895: Test real: Read file \"data/REAL-PD_Test_Data_IDs_Labels_S34_K2.csv\" containing 118 records\n",
      "INFO: 2020-05-18 15:16:54,901: Score: tremor: unique subjects 19:\n",
      "[1004 1006 1007 1019 1020 1023 1032 1034 1038 1043 1046 1048 1049 'hbv013'\n",
      " 'hbv038' 'hbv023' 'hbv054' 'hbv022' 'hbv012']\n",
      "INFO: 2020-05-18 15:16:54,964: Score: dyskinesia: unique subjects 16:\n",
      "[1004 1007 1019 1023 1034 1038 1039 1043 1044 1048 1049 'hbv013' 'hbv017'\n",
      " 'hbv054' 'hbv018' 'hbv043']\n",
      "INFO: 2020-05-18 15:16:55,017: Score: on_off: unique subjects 22:\n",
      "[1004 1006 1007 1019 1020 1023 1032 1034 1038 1039 1043 1044 1048 1049\n",
      " 1051 'hbv013' 'hbv038' 'hbv051' 'hbv077' 'hbv014' 'hbv043' 'hbv022']\n",
      "INFO: 2020-05-18 15:16:55,083: Score tremor - number of feature files 10\n",
      "INFO: 2020-05-18 15:16:55,122: Score dyskinesia - number of feature files 10\n",
      "INFO: 2020-05-18 15:16:55,159: Score on_off - number of feature files 10\n",
      "INFO: 2020-05-18 15:16:56,535: Negative 124 Positive 91 of 354\n",
      "INFO: 2020-05-18 15:16:56,536: Neg 101 of 124 81.5%\n",
      "INFO: 2020-05-18 15:16:56,537: Pos 37 of 91 40.7%\n",
      "INFO: 2020-05-18 15:16:56,632: Negative 75 Positive 70 of 291\n",
      "INFO: 2020-05-18 15:16:56,632: Neg 53 of 75 70.7%\n",
      "INFO: 2020-05-18 15:16:56,633: Pos 48 of 70 68.6%\n",
      "INFO: 2020-05-18 15:16:56,749: Negative 225 Positive 133 of 418\n",
      "INFO: 2020-05-18 15:16:56,750: Neg 164 of 225 72.9%\n",
      "INFO: 2020-05-18 15:16:56,750: Pos 70 of 133 52.6%\n",
      "INFO: 2020-05-18 15:16:56,772: K iterator 3\n",
      "INFO: 2020-05-18 15:16:56,775: Training cis: Read file \"data/CIS-PD_Training_Data_IDs_Labels_S34_K3.csv\" containing 1487 records\n",
      "INFO: 2020-05-18 15:16:56,776: Test cis: Read file \"data/CIS-PD_Test_Data_IDs_Labels_S34_K3.csv\" containing 371 records\n",
      "INFO: 2020-05-18 15:16:56,778: Training real: Read file \"data/REAL-PD_Training_Data_IDs_Labels_S34_K3.csv\" containing 473 records\n",
      "INFO: 2020-05-18 15:16:56,780: Test real: Read file \"data/REAL-PD_Test_Data_IDs_Labels_S34_K3.csv\" containing 118 records\n",
      "INFO: 2020-05-18 15:16:56,786: Score: tremor: unique subjects 19:\n",
      "[1004 1006 1007 1019 1020 1023 1032 1034 1038 1043 1046 1048 1049 'hbv013'\n",
      " 'hbv038' 'hbv023' 'hbv054' 'hbv022' 'hbv012']\n",
      "INFO: 2020-05-18 15:16:56,848: Score: dyskinesia: unique subjects 16:\n",
      "[1004 1007 1019 1023 1034 1038 1039 1043 1044 1048 1049 'hbv013' 'hbv017'\n",
      " 'hbv054' 'hbv018' 'hbv043']\n",
      "INFO: 2020-05-18 15:16:56,902: Score: on_off: unique subjects 22:\n",
      "[1004 1006 1007 1019 1020 1023 1032 1034 1038 1039 1043 1044 1048 1049\n",
      " 1051 'hbv013' 'hbv038' 'hbv051' 'hbv077' 'hbv014' 'hbv043' 'hbv022']\n",
      "INFO: 2020-05-18 15:16:56,968: Score tremor - number of feature files 6\n",
      "INFO: 2020-05-18 15:16:56,992: Score dyskinesia - number of feature files 6\n",
      "INFO: 2020-05-18 15:16:57,014: Score on_off - number of feature files 6\n",
      "INFO: 2020-05-18 15:16:57,872: Negative 92 Positive 92 of 354\n",
      "INFO: 2020-05-18 15:16:57,873: Neg 69 of 92 75.0%\n",
      "INFO: 2020-05-18 15:16:57,874: Pos 40 of 92 43.5%\n",
      "INFO: 2020-05-18 15:16:57,965: Negative 61 Positive 48 of 288\n",
      "INFO: 2020-05-18 15:16:57,966: Neg 54 of 61 88.5%\n",
      "INFO: 2020-05-18 15:16:57,966: Pos 23 of 48 47.9%\n",
      "INFO: 2020-05-18 15:16:58,079: Negative 212 Positive 129 of 423\n",
      "INFO: 2020-05-18 15:16:58,080: Neg 155 of 212 73.1%\n",
      "INFO: 2020-05-18 15:16:58,080: Pos 69 of 129 53.5%\n"
     ]
    }
   ],
   "source": [
    "kscore = {}\n",
    "parms  = { }\n",
    "for K in Ks:\n",
    "    parms [K] = {}\n",
    "    \n",
    "    logging.info(f'K iterator {K}')\n",
    "    training_labels, test_labels, test_data_folder = {}, {}, {}\n",
    "     \n",
    "    for dataset in datasets:\n",
    "        labels_folder = 'data'\n",
    "        test_label_file = os.path.join(labels_folder, dataset.upper()+f'-PD_Test_Data_IDs_Labels_{test_rand}{K}.csv')\n",
    "        training_label_file = os.path.join(labels_folder, dataset.upper()+f'-PD_Training_Data_IDs_Labels_{test_rand}{K}.csv')\n",
    "\n",
    "        training_labels[dataset] = pd.read_csv(training_label_file)\n",
    "        logging.info(f'Training {dataset}: Read file \"{training_label_file}\" containing {training_labels[dataset].shape[0]} records')\n",
    "\n",
    "        test_labels[dataset] = pd.read_csv(test_label_file)\n",
    "        logging.info(f'Test {dataset}: Read file \"{test_label_file}\" containing {test_labels[dataset].shape[0]} records')\n",
    "        \n",
    "    train_df, test_df = {}, {}\n",
    "    subjects, test_subject_sq = {}, {}\n",
    "    for score in score_names:\n",
    "        field_cols = ['measurement_id', 'subject_id', score]\n",
    "        train_df[score] = pd.concat([training_labels['cis'][field_cols], training_labels['real'][field_cols]]).dropna(subset=[score])\n",
    "        test_df[score] = pd.concat([test_labels['cis'][field_cols], test_labels['real'][field_cols]]).dropna(subset=[score])\n",
    "        subjects[score] = train_df[score]['subject_id'].unique()\n",
    "        logging.info(f'Score: {score}: unique subjects {subjects[score].shape[0]}:\\n{subjects[score]}')\n",
    "        test_subject_sq[score] = [np.sqrt((test_df[score]['subject_id']==subject).sum()) for subject in subjects]\n",
    "        for subject in subjects[score]:\n",
    "            test_df[score].loc[test_df[score]['subject_id']==subject, 'naive_mean'] = train_df[score][train_df[score]['subject_id']==subject][score].mean()\n",
    "            test_df[score].loc[test_df[score]['subject_id']==subject, 'naive_std'] = train_df[score][train_df[score]['subject_id']==subject][score].std()\n",
    "        test_df[score].set_index('measurement_id', inplace=True)\n",
    "\n",
    "    for score in score_names:        \n",
    "        feature_results = sorted(glob.glob(f'features/{test_rand}{K}/*{score}_*.csv'))\n",
    "        logging.info(f'Score {score} - number of feature files {len(feature_results)}')\n",
    "        for i, file_name in enumerate(feature_results):\n",
    "            d = pd.read_csv(file_name).set_index('measurement_id')\n",
    "            test_df[score][f'f{i}'] = d['prediction']\n",
    "            idx = test_df[score][f'f{i}'].isna() & ~test_df[score]['naive_mean'].isna()\n",
    "            test_df[score].loc[idx,f'f{i}'] = test_df[score].loc[idx,'naive_mean']      \n",
    "\n",
    "    ### Generate a single dataframe\n",
    "\n",
    "    for j, score in enumerate(score_names):\n",
    "        feature_cols = test_df[score].filter(regex='^f')\n",
    "        test_df[score]['f_mean'] = feature_cols.mean(axis=1)\n",
    "        test_df[score]['f_std'] = feature_cols.std(axis=1)\n",
    "        test_df[score]['f_median'] = feature_cols.median(axis=1)\n",
    "        for i, subject in enumerate(subjects[score]):\n",
    "            for feature_col in feature_cols:\n",
    "                test_df[score].loc[test_df[score]['subject_id']==subject,'a'+feature_col[1:]] = (\n",
    "                    test_df[score].loc[test_df[score]['subject_id']==subject, feature_col] - \n",
    "                    test_df[score].loc[test_df[score]['subject_id']==subject, feature_col].mean() +\n",
    "                    test_df[score].loc[test_df[score]['subject_id']==subject, 'naive_mean'].mean() )\n",
    "\n",
    "        adjusted_cols = test_df[score].filter(regex='^a')\n",
    "        test_df[score]['a_mean'] = adjusted_cols.mean(axis=1)\n",
    "        test_df[score]['a_std'] = adjusted_cols.std(axis=1)\n",
    "        test_df[score]['a_median'] = adjusted_cols.median(axis=1)\n",
    "\n",
    "    score_df = pd.DataFrame()\n",
    "    for score in score_names:\n",
    "        score_df.loc['naive', score] = BEATPD_loss(test_df[score],score,'naive_mean')\n",
    "        score_df.loc['f_mean', score] = BEATPD_loss(test_df[score],score,'f_mean')\n",
    "        score_df.loc['a_mean', score] = BEATPD_loss(test_df[score],score,'a_mean')\n",
    "        \n",
    "        parms[K][(score, 'score', 'naive')] = kloss(test_df[score],score,'naive_mean')\n",
    "        parms[K][(score, 'score', 'ayala')] = kloss(test_df[score],score,'a_mean')\n",
    "\n",
    "        negfactor=0\n",
    "        posfactor=0\n",
    "        sneg=test_df[score][(test_df[score]['a_mean']+negfactor*test_df[score]['a_std']<test_df[score]['naive_mean'])  ]\n",
    "        spos=test_df[score][(test_df[score]['a_mean']-posfactor*test_df[score]['a_std']>test_df[score]['naive_mean'])  ]\n",
    "        \n",
    "        if dropNaive:\n",
    "            naive = naive_df[naive_df[score]].index.tolist()\n",
    "            sneg = sneg[~sneg['subject_id'].isin(naive)]\n",
    "            spos = spos[~spos['subject_id'].isin(naive)]\n",
    "        if onlyGood:\n",
    "            good = good_df[good_df[score]].index.tolist()\n",
    "            sneg = sneg[sneg['subject_id'].isin(good)]\n",
    "            spos = spos[spos['subject_id'].isin(good)]\n",
    "\n",
    "        logging.info(f'Negative {sneg.shape[0]} Positive {spos.shape[0]} of {test_df[score].shape[0]}')\n",
    "        logging.info(f\"Neg {(sneg[score]<sneg['naive_mean']).sum()} of {sneg.shape[0]} {100*(sneg[score]<sneg['naive_mean']).sum()/sneg.shape[0]:.1f}%\")\n",
    "        logging.info(f\"Pos {(spos[score]>spos['naive_mean']).sum()} of {spos.shape[0]} {100*(spos[score]>spos['naive_mean']).sum()/spos.shape[0]:.1f}%\")\n",
    "        test_df[score]['cherry'] = test_df[score]['naive_mean']\n",
    "        #test_df[score].loc[sneg.index, 'cherry'] = sneg['a_mean'] + (sneg['a_mean']-sneg['naive_mean']) * 0.5\n",
    "        #test_df[score].loc[spos.index, 'cherry'] = spos['a_mean'] + (spos['a_mean']-spos['naive_mean']) * 0.5\n",
    "        test_df[score].loc[sneg.index, 'cherry'] = sneg['a_mean'] \n",
    "        test_df[score].loc[spos.index, 'cherry'] = spos['a_mean'] \n",
    "        score_df.loc['cherry', score] = BEATPD_loss(test_df[score],score,'cherry')\n",
    "    parms[K]['score'] = score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          tremor  dyskinesia    on_off\n",
      "naive   0.428946    0.418017  1.025418\n",
      "f_mean  0.426847    0.416707  0.993706\n",
      "a_mean  0.403580    0.392489  0.936373\n",
      "cherry  0.383735    0.385744  0.931518\n",
      "          tremor  dyskinesia    on_off\n",
      "naive   0.507345    0.390019  0.932581\n",
      "f_mean  0.477495    0.355379  0.986204\n",
      "a_mean  0.462056    0.368145  0.913249\n",
      "cherry  0.458789    0.347137  0.905802\n",
      "          tremor  dyskinesia    on_off\n",
      "naive   0.368933    0.406923  0.932095\n",
      "f_mean  0.341806    0.388815  0.969064\n",
      "a_mean  0.336872    0.382983  0.869295\n",
      "cherry  0.330117    0.369730  0.859071\n",
      "          tremor  dyskinesia    on_off\n",
      "naive   0.419708    0.415160  1.043055\n",
      "f_mean  0.408859    0.411902  1.122499\n",
      "a_mean  0.395437    0.399446  0.948137\n",
      "cherry  0.393385    0.375855  0.947961\n"
     ]
    }
   ],
   "source": [
    "for K in Ks:\n",
    "    print(parms[K]['score'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
